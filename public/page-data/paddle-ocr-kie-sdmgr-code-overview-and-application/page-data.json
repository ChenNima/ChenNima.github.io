{"componentChunkName":"component---src-templates-blog-post-tsx","path":"/paddle-ocr-kie-sdmgr-code-overview-and-application","result":{"data":{"markdownRemark":{"html":"<p>在上篇文章<a href=\"/cuda-gpu-setup-for-paddle-on-windows-wsl\">Windows环境下利用WSL搭建GPU训练/推理PaddlePaddle神经网络环境</a>中我们简单介绍了如何在Windows的WSL2环境中搭建PaddlePaddle的GPU训练/推理环境，那么这次就来结合代码一起来看看PaddleOCR中KIE模块: SDMGR网络的代码与如何推理/训练吧。</p>\n<h1>1. 什么是KIE任务与SDMGR网络</h1>\n<p>KIE(Key Infomation Extraction)即关键信息提取是计算机视觉任务中的一种，目的是在给定的图片以及其他信息中提取关键信息。例如这次要介绍的SDMGR网络，在给定图片以及图片中文字的位置和内容后，可以给文字信息分类。比如在<a href=\"https://paperswithcode.com/dataset/wildreceipt\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">WildReceipt</a>这个英文小票的数据集上训练好的SDMGR模型，可以在给定图片和文字后提取出如下信息：</p>\n<p><span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 348px; '>\n      <a class='gatsby-resp-image-link' href='/static/190af73b36d885ab20d2149cbaa1c053/34ea4/receipt.png' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEB0lEQVQ4yxVTy47bVAA1ReoCVvABCPEPLEBiiQRLpCIBLYsi2mmn7SSdZCZPJ7bj+G3fa99rX9/r9yNxnpNJpy1F/TnC0dke6Tx0uM3th2r3rtq/LzZ32f79Il5YU0XtTeZDIdYdS9D0gTi/HmcG3KjOZqomdpA0x18ePuZOoPmqzNeV6dVhviQ5lDT+ejwfiXA6MyTVEFSzM2jzskizIK68MLOjijaHh09f/S9mZQ1Wt4pixbarTiRlyGuKpgI46/ZkD3fDqIfJKxy2/KgFyJkGL4OELPaPzi+4e59wxc2m+eejub+dF5UXhGA8hbM5Y7Gkm4okX0Kvn6Qdn/wlKy2Az0zIpzWrds86vXv373PFbrt69yF785b8+9Fo1iPTuVb1rm69lBVUVL04feqivwHspNn1slFXa1A2ZHXsavann3/GNYfDcXuzX2936+26KOuyzvNqEYZxUSZNk6apH6eIUpZmQVbkCKUQ54j5E+mbL7/g6rfvsIuxqgVVXQpSMhyHmpbyPNE0FwANuFFVmmEoDIYq9Mzh2O10bUldac73X33Nrd68Z9s92e7p8Y7sb/ybfbDdBJs1WSxIUbhpEqyW5nIplpVV1Uaaz4tSTXI/W3z73Q/c9vi2iJLS9ZZ+0EBUU5pDsHPhEnlrRrcBjrOELiq2XpkIORPB5qez3ih28IMff+LWhyPwsKEarmEj24G+r2pKZFsu8qoAbaBDy9yvy5ORrmG1u/2rHv+qM2BB8vdvj7j65va0kI+JbdgUYZwmtqpQ71QDqgO8cgGrCpTnMIq60HsiyKOR0L4cUI/OXrQ4djjOZdVW9JQwacwrtoUd2zMNDEENnLVleWXuxLEehFZAznvj4WXvss8jHVAVcPT2znGRC5Fh2NiBhocMSYqA4zPW0PCUnMWxExIrZGMXPx6MxZl63uNnFvJtn4sOb+Bm7+0O2qLxbo5wt1eSGNu2qeuBogB5Di5auufZLJ4FpONinmZXOBJJNicZd6ibu7Q4xOkmKzbl4hinAWVA0TRBvLKcruU8k+QhoUbIdJ8ASXVEFQiKJZuWDjhA0+lE0OaaPpWkuVbSeEHjNMmiJHVPn8lLOyt0Ghk+GYXRn89bvevxWbt3xc9cxeYskomCYgAUI98Lowr5FWG4XrppDlhshfQk0wOiICIj9tpwX1xctfvC66tRIGqcTTJlIFqILaNshcOM0Nq0wzACcWpRpgdMRVT2iAj9mR28nipPnrXaQ/G8PwWCyqk4MvqT6VCiMKyBn7iYQgQI0wlTvVAGRLJ9wcJT3R1b+GT76a+POi86L88uZqLBTdLF8zBpuwHRYazDbKo4LlVRpAAimIjX4EhxThzMzL5sPZibP0/k3yH5Q7H5sfofM4uYbkwjNf4AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='WildReceipt' title='WildReceipt' src='/static/190af73b36d885ab20d2149cbaa1c053/34ea4/receipt.png' srcset='/static/190af73b36d885ab20d2149cbaa1c053/4edbd/receipt.png 175w,\n/static/190af73b36d885ab20d2149cbaa1c053/34ea4/receipt.png 348w' sizes='(max-width: 348px) 100vw, 348px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy'>\n  </a>\n    </span></p>\n<p>可以看到在图中标红的部分就是对小票OCR出的文字框的分类，目前这个预训练的模型可以较为准确地识别英文小票中店名，店地址，商品名，单价，总价，税额之类的关键信息。由于SDMGR网络专注于在双模态(即图片与文字信息)中提取关键信息，在使用前需要对整张图片进行一次OCR来获得文字的内容和位置信息。</p>\n<p><a href=\"https://arxiv.org/abs/2103.14470v1\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SDMGR/SDMG-R</a>(Spatial Dual-Modality Graph Reasoning for Key Information Extraction)网络的论文是2021年由商汤递交，默认的实现在<a href=\"https://github.com/open-mmlab/mmocr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MMOCR</a>中。该网络的名字念起来比较拗口，我们先来看一眼整个网络的结构：</p>\n<p><span class='gatsby-resp-image-wrapper' style='position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 700px; '>\n      <a class='gatsby-resp-image-link' href='/static/9f2841aa6e29db8849739d5cc5f853a4/56873/sdmgr-net.jpg' style='display: block' target='_blank' rel='noopener'>\n    <span class='gatsby-resp-image-background-image' style=\"padding-bottom: 46.28571428571429%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDAgX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHt6mygg//EABcQAAMBAAAAAAAAAAAAAAAAAAABEEH/2gAIAQEAAQUC0VR//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhAAAwAAAAAAAAAAAAAAAAAAACAx/9oACAEBAAY/Air/AP/EABwQAAEEAwEAAAAAAAAAAAAAAAABESExEEFhof/aAAgBAQABPyFpT6PwUlXNrip//9oADAMBAAIAAwAAABBwD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAAICAQUAAAAAAAAAAAAAAAERACExEGFxofH/2gAIAQEAAT8QQEJ2dijeEdkWyIO/TLzP/9k='); background-size: cover; display: block;\"></span>\n  <img class='gatsby-resp-image-image' alt='sdmgr-net' title='sdmgr-net' src='/static/9f2841aa6e29db8849739d5cc5f853a4/29d31/sdmgr-net.jpg' srcset='/static/9f2841aa6e29db8849739d5cc5f853a4/e52aa/sdmgr-net.jpg 175w,\n/static/9f2841aa6e29db8849739d5cc5f853a4/70ebb/sdmgr-net.jpg 350w,\n/static/9f2841aa6e29db8849739d5cc5f853a4/29d31/sdmgr-net.jpg 700w,\n/static/9f2841aa6e29db8849739d5cc5f853a4/9ecec/sdmgr-net.jpg 1050w,\n/static/9f2841aa6e29db8849739d5cc5f853a4/d165a/sdmgr-net.jpg 1400w,\n/static/9f2841aa6e29db8849739d5cc5f853a4/56873/sdmgr-net.jpg 2332w' sizes='(max-width: 700px) 100vw, 700px' style='width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;' loading='lazy'>\n  </a>\n    </span></p>\n<p>总的来说网络分为三个层次：</p>\n<ol>\n<li>Backbone部分一方面使用<a href=\"https://arxiv.org/abs/1505.04597\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">U-Net</a>卷积网络提取图片的视觉特征，经过一个<code class=\"language-text\">ROI Pooling</code>抽取对应各个文字框的特征图，另一方面使用<a href=\"https://paperswithcode.com/method/bilstm\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">双向LSTM</a>(实际代码不论PaddleOCR还是MMOCR，都使用了LSTM而不是Bi-LSTM)提取文字特征。最后使用<code class=\"language-text\">Kronecker乘积</code>结合了视觉特征和文字特征输出给后续模块</li>\n<li>Neck部分将结合后的特征作为节点放入一个图神经网络进行迭代，而图网络的边则是由文字节点之间的空间信息构成的。</li>\n<li>Head部分将图网络的节点和边输出各过了一个全连接层转换到对应分类的数量，最后通过一个<code class=\"language-text\">softmax</code>输出分类结果。</li>\n</ol>\n<p>结合整个网络的结构，论文的几个关键字就好理解了：</p>\n<ol>\n<li>Spatial: 指文字节点间的空间信息，用于图神经网络中的边</li>\n<li>Dual-Modality：双模态指的是视觉和文字信息，分别抽取后做<code class=\"language-text\">Kronecker乘积</code>形成图神经网络中的节点</li>\n<li>Graph Reasoning：利用图推理模模块的迭代来优化节点特征</li>\n</ol>\n<p>对于论文更详细的解读可以参考B站视频</p>\n<ul>\n<li><a href=\"https://www.bilibili.com/video/BV1K44y1M7ah\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">AI论文精读之SDMGR</a></li>\n</ul>\n<p>以及两篇文章</p>\n<ul>\n<li><a href=\"https://blog.csdn.net/shiwanghualuo/article/details/122315487\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">论文阅读: Spatial Dual-Modality Graph Reasoning for Key Information Extraction (关键信息提取算法)</a></li>\n<li><a href=\"https://blog.csdn.net/sinat_33455447/article/details/122987871\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SDMGR模型学习笔记</a></li>\n</ul>\n<p>我们也会在之后的文章中对PaddleOCR中的代码实现进行精读。</p>\n<h1>2. 模型配置概览</h1>\n<p>在PaddleOCR中，每个模型除了代码实现之外，还需要一个配置文件将各个模块组织起来，这样就可以利用PaddleOCR自带的训练工具进行训练了。而这个配置文件则是带领我们认识整个模型最好的切入点。在阅读代码或是下载预训练模型进行推理之前，让我们阅读一下SDMGR网络的配置文件吧</p>\n<p>由于有一部分配置文件指向了数据集中文件，不妨先下载数据集</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># 进入项目</span>\n<span class=\"token builtin class-name\">cd</span> PaddleOCR/\n<span class=\"token comment\"># 下载wildreceipt数据集并解压</span>\n<span class=\"token function\">wget</span> https://paddleocr.bj.bcebos.com/dygraph_v2.1/kie/wildreceipt.tar <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">tar</span> xf wildreceipt.tar\n<span class=\"token comment\"># 将数据集链接至train_data目录下</span>\n<span class=\"token function\">mkdir</span> train_data <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> train_data\n<span class=\"token function\">ln</span> -s <span class=\"token punctuation\">..</span>/<span class=\"token punctuation\">..</span>/wildreceipt ./</code></pre></div>\n<p>接下来我们来看配置文件: <code class=\"language-text\">configs/kie/kie_unet_sdmgr.yml</code> (以下代码仅保留关键部分)</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">Global</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token comment\"># 信息分类文件</span>\n  <span class=\"token key atrule\">class_path</span><span class=\"token punctuation\">:</span> ./train_data/wildreceipt/class_list.txt\n  <span class=\"token comment\"># 图片缩放大小</span>\n  <span class=\"token key atrule\">img_scale</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span> <span class=\"token number\">1024</span><span class=\"token punctuation\">,</span> <span class=\"token number\">512</span> <span class=\"token punctuation\">]</span>\n\n<span class=\"token key atrule\">Architecture</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">Backbone</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># ppocr/modeling/backbones/kie_unet_sdmgr.py</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> Kie_backbone\n  <span class=\"token key atrule\">Head</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># ppocr/modeling/heads/kie_sdmgr_head.py</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> SDMGRHead\n    <span class=\"token comment\"># 添加以下两个参数来适配自定义的字典文件与分类文件</span>\n    <span class=\"token comment\"># num_chars: 92</span>\n    <span class=\"token comment\"># num_classes: 26</span>\n\n<span class=\"token key atrule\">Loss</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># ppocr/losses/kie_sdmgr_loss.py</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> SDMGRLoss\n\n<span class=\"token key atrule\">Optimizer</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># ppocr/optimizer/optimizer.py</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> Adam\n  <span class=\"token punctuation\">...</span>\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">Metric</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># ppocr/metrics/kie_metric.py</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> KIEMetric\n  <span class=\"token key atrule\">main_indicator</span><span class=\"token punctuation\">:</span> hmean\n\n<span class=\"token key atrule\">Train</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">dataset</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">...</span>\n    <span class=\"token key atrule\">label_file_list</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span> <span class=\"token string\">'./train_data/wildreceipt/wildreceipt_train.txt'</span> <span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">ratio_list</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span> <span class=\"token number\">1.0</span> <span class=\"token punctuation\">]</span>\n    <span class=\"token key atrule\">transforms</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">...</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">KieLabelEncode</span><span class=\"token punctuation\">:</span>\n          <span class=\"token comment\"># 字典文件</span>\n          <span class=\"token key atrule\">character_dict_path</span><span class=\"token punctuation\">:</span> ./train_data/wildreceipt/dict.txt\n      <span class=\"token comment\"># 使用Global.img_scale的配置对图片缩放</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">KieResize</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">ToCHWImage</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">Eval</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">dataset</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">...</span></code></pre></div>\n<p>我们逐条来看各个配置包含的信息:</p>\n<ul>\n<li>\n<p>Global</p>\n<ul>\n<li><code class=\"language-text\">class_path</code>: 指向了分类文件，该文件每一行代表了最终对文字的一个分类。默认的wildreceipt数据集有26个分类，如果你希望训练自己的模型，那么你大概率需要自己定义一个文件包含你所有的class。 <strong>特别注意：如果你修改了class的数量，需要同时修改<code class=\"language-text\">SDMGRHead</code>初始化的<code class=\"language-text\">num_classes</code>参数以及<code class=\"language-text\">KIEMetric</code>中<code class=\"language-text\">compute_f1_score</code>的<code class=\"language-text\">ignores</code>。在下文中会详细介绍</strong></li>\n<li><code class=\"language-text\">img_scale</code>: 将图片的长边限制在1024像素，短边限制在512像素，这个选项仅在<code class=\"language-text\">Train.dataset.transforms.KieResize</code>启用时生效</li>\n</ul>\n</li>\n<li>\n<p>Architecture</p>\n<ul>\n<li><code class=\"language-text\">Backbone</code>: 整个Backbone代码的位置在<code class=\"language-text\">ppocr/modeling/backbones/kie_unet_sdmgr.py</code>，与上文中图片划分出网络的三个模块不同，代码中的Backbone仅包含U-Net卷积网络，并不包含文字的处理。</li>\n<li><code class=\"language-text\">Head</code>: 代码位置在<code class=\"language-text\">ppocr/modeling/heads/kie_sdmgr_head.py</code>由于没有代码没有Neck层，<code class=\"language-text\">LSTM</code>，<code class=\"language-text\">Kronecker乘积</code>，图推理和最后的两个全连接代码全在Head模块中了。这个模块也是整个网络中最重要的模块，如果修改了class数量或者文字embedding用字典文件，都需要修改配置文件添加<code class=\"language-text\">num_chars</code>和<code class=\"language-text\">num_classes</code>参数，下文中会详细介绍。</li>\n</ul>\n</li>\n<li>Loss: 代码位置在<code class=\"language-text\">ppocr/losses/kie_sdmgr_loss.py</code>，分别对网络中输出的<code class=\"language-text\">node</code>和<code class=\"language-text\">edge</code>做交叉熵loss并相加获得总loss(默认权重都是1)。</li>\n<li>Optimizer： 默认使用Adam作为优化器</li>\n<li>Metric: 代码位置在<code class=\"language-text\">ppocr/metrics/kie_metric.py</code>。评估模型使用了节点的<a href=\"https://en.wikipedia.org/wiki/F-score\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">F1-score</a>，即对文字分类的精度(precision)和召回(recall)做了调和平均。需要注意的是部分类在计算F1时被忽略了，包括了<code class=\"language-text\">Ignore</code>，<code class=\"language-text\">Other</code>以及各种key，如果你修改了class文件，那么也要相应地调整<code class=\"language-text\">ppocr/metrics/kie_metric.py</code>中的<code class=\"language-text\">ignores</code>数组。</li>\n<li>\n<p>Train</p>\n<ul>\n<li><code class=\"language-text\">label_file_list</code>: 指向了训练数据集，PaddleOCR版本的数据集使用了类似于<code class=\"language-text\">tsv</code>格式，即<code class=\"language-text\">图片位置\\t标号</code>。</li>\n<li><code class=\"language-text\">ratio_list</code>: 如果指定了多个<code class=\"language-text\">label_file</code>, 则可以分别指定各个<code class=\"language-text\">label_file</code>在每个训练epoch中采样的比例。</li>\n<li><code class=\"language-text\">transforms</code>:</li>\n<li><code class=\"language-text\">KieLabelEncode</code>: 指定了用于embedding文字信息的字典文件位置。Wildreceipt数据集自带了英文字典文件，如果你希望使用中文字典，可以使用PaddleOCR自带的中文字典<code class=\"language-text\">ppocr/utils/ppocr_keys_v1.txt</code>。需要注意如果修改了字典文件，配置文件中<code class=\"language-text\">SDMGRHead</code>的参数<code class=\"language-text\">num_chars</code>参数为<code class=\"language-text\">字典长度 + 1</code>。如果你使用了<code class=\"language-text\">ppocr_keys_v1.txt</code>，那么这个值是6624。</li>\n</ul>\n</li>\n<li>Eval: 基本同<code class=\"language-text\">Train</code></li>\n</ul>\n<h1>3. 使用模型</h1>\n<p>首先让我们在wildreceipt数据集上跑一下预训练模型把。数据集在上面已经下载过了，我们直接来下载模型参数：</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># 进入项目位置</span>\n<span class=\"token builtin class-name\">cd</span> PaddleOCR\n<span class=\"token comment\"># 下载并解压预训练参数</span>\n<span class=\"token function\">wget</span> https://paddleocr.bj.bcebos.com/dygraph_v2.1/kie/kie_vgg16.tar <span class=\"token operator\">&amp;&amp;</span> <span class=\"token function\">tar</span> xf kie_vgg16.tar</code></pre></div>\n<p>完成后预训练参数在<code class=\"language-text\">kie_vgg16</code>目录下。比较关键的两个文件<code class=\"language-text\">kie_vgg16/best_accuracy.pdopt</code>和<code class=\"language-text\">kie_vgg16/best_accuracy.pdparams</code>分别是优化器参数和模型参数。由于SDMGR的模型源码是本地的python文件，就不需要再下载一个模型文件了。</p>\n<p>现在使用自带的infer工具可以进行推理：</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> PaddleOCR\npython tools/infer_kie.py -c configs/kie/kie_unet_sdmgr.yml -o Global.checkpoints<span class=\"token operator\">=</span>kie_vgg16/best_accuracy  Global.infer_img<span class=\"token operator\">=</span>train_data/wildreceipt/1.txt</code></pre></div>\n<p>此处<code class=\"language-text\">-o</code>可以覆盖指定config文件中的配置。这里使用<code class=\"language-text\">kie_vgg16</code>下<code class=\"language-text\">best_accuracy</code>为前缀的两个参数文件推理模型，并将结果储存在<code class=\"language-text\">output/sdmgr_kie/kie_results</code>中。打开该文件夹即可看到图片推理的结果。</p>\n<p>同样的，使用工具也可以在数据集上训练模型:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">python tools/train.py -c configs/kie/kie_unet_sdmgr.yml -o Global.save_model_dir<span class=\"token operator\">=</span>./output/kie/</code></pre></div>\n<p>需要注意的是模型训练时对显存压力比较大，<code class=\"language-text\">batchSize</code>为1的情况也要消耗约5-6G的显存。如果训练过程中显存爆了可以酌情降低配置文件中的<code class=\"language-text\">Train.loader.batch_size_per_card</code>选项。</p>\n<p>在动手尝试过后，让我们认识一下数据文件的格式吧。PaddleOCR所使用到的训练集，验证集和测试集分别是<code class=\"language-text\">train_data/wildreceipt/wildreceipt_train.txt</code>, <code class=\"language-text\">train_data/wildreceipt/wildreceipt_test.txt</code>和<code class=\"language-text\">train_data/wildreceipt/1.txt</code>。这三个文件的格式都是一样的。每一行代表一条数据，格式为<code class=\"language-text\">图片位置\\t标号</code>。图片位置信息比较好理解，图片标号则是一个JSON Array, Array中每一项代表一条文字信息以及其位置信息。将这个JSON格式化后如下:</p>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\"><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token property\">\"label\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"transcription\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ILIO'S\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token property\">\"points\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">[</span>\n                <span class=\"token number\">372.0</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">242.0</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span>\n                <span class=\"token number\">479.0</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">242.0</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span>\n                <span class=\"token number\">479.0</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">178.0</span>\n            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            <span class=\"token punctuation\">[</span>\n                <span class=\"token number\">372.0</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">178.0</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    ...\n<span class=\"token punctuation\">]</span></code></pre></div>\n<p>可以看到每个文字标号包含三个key：</p>\n<ul>\n<li>label：文字的分类，与class文件中的分类一一对应。例子中的<code class=\"language-text\">1</code>就对应了<code class=\"language-text\">Store_name_value</code>。</li>\n<li>transcription： 文字内容</li>\n<li>points：文字坐标，从左上角顺时针排列</li>\n</ul>\n<p>训练、验证、测试集的格式都是一样的，上文尝试在<code class=\"language-text\">train_data/wildreceipt/1.txt</code>数据集上进行推理，而该文件的每个标号上都已经含有正确的<code class=\"language-text\">label</code>，并且如果将<code class=\"language-text\">label</code>这项去掉，模型会因缺少参数报错。也就意味着要进行推理，我要实现知道各个文字的分类，岂不是很奇怪？其实这里的<code class=\"language-text\">label</code>只是为了满足模型参数的输入形状，实际上模型并不会真的在推理的收去看这一项。也就是说在进行推理的时候，<code class=\"language-text\">label</code>字段随便填一个值就可以了，并不会影响结果。</p>\n<h1>4. 应用模型</h1>\n<p>模型自带的预训练参数效果很不错，但是应用场景也仅仅是对英文小票的识别而已。如何将这个模型应用到其他领域呢？总的来说，有以下几个步骤。</p>\n<h2>4.1 制作分类文件</h2>\n<p>在制作数据集前应当先确定任务的目标：需要将图片中的文字分成哪些类？wildreceipt数据集中的分类又主要分为四种：</p>\n<ul>\n<li>Ignore: 如果文字内容为空则没有意义，应当标注为<code class=\"language-text\">Ignore</code></li>\n<li>Others: 该文字内容并不是关键信息，则标注为<code class=\"language-text\">Others</code>，即负类</li>\n<li>Keys: 如果你要提取的关键信息是Key-Value pair，那么标注的时候可以将<code class=\"language-text\">Key</code>单独标注，比如<code class=\"language-text\">Store_name_key</code>，不过Keys在验证阶段是不参与计算<code class=\"language-text\">F1 score</code>的。虽然对最终提取出的关键信息来说，<code class=\"language-text\">Keys</code>是没有价值的，但是论文中提到对<code class=\"language-text\">Keys</code>的正确识别可以提升关键信息<code class=\"language-text\">Values</code>识别的准确率。</li>\n<li>Values: 这就是你希望提取的关键信息了。</li>\n</ul>\n<p>在以上四大类中，<code class=\"language-text\">Ignore</code>， <code class=\"language-text\">Others</code>和<code class=\"language-text\">Keys</code>都是不参与模型评估的，也就是说模型的<code class=\"language-text\">F1 score</code>是完全取决于Values的分类精度和召回。<strong>决定一个class是不是参与模型验证的是<code class=\"language-text\">ppocr/metrics/kie_metric.py</code>中<code class=\"language-text\">compute_f1_score</code>函数的<code class=\"language-text\">ignores</code>数组</strong>。 默认<code class=\"language-text\">ignores = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 25]</code>就一一对应了<code class=\"language-text\">train_data/wildreceipt/class_list.txt</code>中的<code class=\"language-text\">Ignore</code>， <code class=\"language-text\">Others</code>和<code class=\"language-text\">Keys</code>。<strong>如果你不修改这个数组来对应你自己的class文件，那么很可能模型验证阶段给出的<code class=\"language-text\">F1 score</code>是不正确的</strong></p>\n<p>另外配置文件中<code class=\"language-text\">Architecture.Head.num_classes</code>参数也要被修改为<code class=\"language-text\">class数 + 1</code>。</p>\n<h2>4.2 制作数据集</h2>\n<p>制作数据集自然是最重要的步骤。需要注意的是SDMGR模型在推理阶段需要很多的数据，包括图片，文字信息和文字位置。在推理阶段文字信息和文字位置大概率是从某个前置的OCR网络中输出出来的。这也就意味着在制作数据集的阶段，文字内容和位置信息最好也使用与未来推理阶段相同的OCR网络来生成，最后再手动对各个文字框进行标号。如果制作数据集时手动画了文字的边界框以及标注文字内容，那么很容易造成模型训练完后推理时受OCR输出的结果不准确而影响分类的效果。</p>\n<h2>4.3 选择合适的字典</h2>\n<p>如果你的任务中文字是英文加常见标点，那么可以直接使用wildreceipt自带的字典文件，也不需要修改代码。但如果你的任务涉及到其他语言或者符号，那么就需要使用对应的字典了。PaddleOCR内置了包括中文，日语，韩文，法文，德文等在内的字典文件，具体位置可以参考<a href=\"https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/doc/doc_ch/recognition.md\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">文档</a>。在修改字典文件后要记得同时修改配置文件中<code class=\"language-text\">Architecture.Head.num_chars</code>参数为<code class=\"language-text\">字典长度 + 1</code>，这样输入的文字才能正确地被embedding。</p>\n<h1>5.总结</h1>\n<p>今天这篇文章从模型配置的角度介绍了<code class=\"language-text\">PaddleOCR</code>中实现的<code class=\"language-text\">SDMGR</code>关键信息提取网络总体的代码框架，以及在实践过程中的一些坑。下一篇文章会从更详细的代码角度逐个模块地讲解整个网络。</p>\n<p><a href=\"/paddle-ocr-kie-sdmgr-code-data-process-and-backbone\">关键信息提取网络SDMGR代码详解(2): 数据处理与主干网络</a></p>\n<p><a href=\"/paddle-ocr-kie-sdmgr-code-embedding-lstm-and-gnn\">关键信息提取网络SDMGR代码详解(3): 循环神经网络与图神经网络</a></p>\n<p><a href=\"/paddle-ocr-kie-sdmgr-loss-and-evaluation\">关键信息提取网络SDMGR代码详解(4): 损失函数与模型评估</a></p>\n<h3>参考链接</h3>\n<ol>\n<li><a href=\"https://arxiv.org/abs/2103.14470v1\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/abs/2103.14470v1</a></li>\n<li><a href=\"https://github.com/open-mmlab/mmocr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/open-mmlab/mmocr</a></li>\n<li><a href=\"https://arxiv.org/abs/1505.04597\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://arxiv.org/abs/1505.04597</a></li>\n<li><a href=\"https://paperswithcode.com/method/bilstm\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://paperswithcode.com/method/bilstm</a></li>\n<li><a href=\"https://www.bilibili.com/video/BV1K44y1M7ah\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.bilibili.com/video/BV1K44y1M7ah</a></li>\n<li><a href=\"https://paperswithcode.com/dataset/wildreceipt\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://paperswithcode.com/dataset/wildreceipt</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/F-score\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://en.wikipedia.org/wiki/F-score</a></li>\n</ol>","excerpt":"在上篇文章Windows环境下利用WSL搭建GPU训练/推理PaddlePaddle神经网络环境中我们简单介绍了如何在Windows的WSL2环境中搭建PaddlePaddle的GPU训练/推理环境，那么这次就来结合代码一起来看看PaddleOCR中KIE模块: SDMGR网络的代码与如何推理/训练吧。 1. 什么是KIE任务与SDMGR网络 KIE(Key Infomation Extraction…","frontmatter":{"date":"June 27, 2022","path":"/paddle-ocr-kie-sdmgr-code-overview-and-application","title":"关键信息提取网络SDMGR代码详解(1): 概览与应用"}}},"pageContext":{}},"staticQueryHashes":["1176552510","3649515864","63159454","846684790"]}